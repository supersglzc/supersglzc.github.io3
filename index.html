<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<head>
    <meta name=viewport content="width=device-width, initial-scale=1">
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <style type="text/css">
        /* Color scheme stolen from Sergey Karayev */
        
        a {
            color: #1772d0;
            text-decoration: none;
        }
        
        a:focus,
        a:hover {
            color: #f09228;
            text-decoration: none;
        }
        
        body,
        td,
        th,
        tr,
        p,
        a {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 15px
        }
        
        strong {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 15px;
        }
        
        heading {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 24px;
        }
        
        papertitle {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 15px;
            font-weight: 700
        }
        
        name {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 32px;
        }
        
        .one {
            width: 160px;
            height: 160px;
            position: relative;
        }
        
        .two {
            width: 160px;
            height: 160px;
            position: absolute;
            transition: opacity .2s ease-in-out;
            -moz-transition: opacity .2s ease-in-out;
            -webkit-transition: opacity .2s ease-in-out;
        }
        
        .fade {
            transition: opacity .2s ease-in-out;
            -moz-transition: opacity .2s ease-in-out;
            -webkit-transition: opacity .2s ease-in-out;
        }
        
        span.highlight {
            background-color: #ffffd0;
        }
    </style>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
    <!-- https://fontawesome.com/cheatsheet -->
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.3.1/css/all.css" integrity="sha384-mzrmE5qonljUremFsqc01SB46JvROS7bZs3IO2EmfFsd15uHvIt+Y8vEf7N7fWAU" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">
    <link rel="icon" type="image/png" href="images/selfie.jpg">
    <title>Steven (Zechu) Li</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <link href='https://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
</head>
<script>
    function toggleblock(blockId) {
        var block = document.getElementById(blockId);
        if (block.style.display == 'none') {
            block.style.display = 'block';
        } else {
            block.style.display = 'none';
        }
    }

    function hideblock(blockId) {
        var block = document.getElementById(blockId);
        block.style.display = 'none';
    }
</script>
<!-- Place this tag in your head or just before your close body tag. -->
<script async defer src="https://buttons.github.io/buttons.js"></script>

<body>
    <table width="1000" border="0" align="center" cellspacing="0" cellpadding="0">
        <tr>
            <td>
                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tr>
                        <td width="67%" valign="middle">
                            <p align="center">
                                <name>Steven (Zechu) Li </name>
                            </p>
                            <p>
                                I am currently a visiting researcher at at <a href="https://www.csail.mit.edu/" target="_blank">MIT CSAIL</a>, advised by Prof. <a href="http://people.csail.mit.edu/pulkitag/" target="_blank">Pulkit Agrawal</a>. My research interests
                                revolve around the intersection of robot learning (dexterous manipulation, locomotion, navigation).
                            </p>
                            <p>
                                Prior to this, I received my bachelor's degree from <a href="https://www.columbia.edu/" target="_blank">Columbia University (CU)</a> in May 2022, majoring in <b>computer science</b>.
                            </p>
                           
                            <p align=center>
                                <a href="mailto:zechu@mit.edu">Email</a> &nbsp/&nbsp
                                <a href="files/taochen_cv.pdf" target="_blank">CV</a> &nbsp/&nbsp
                                <a href="https://scholar.google.com/citations?user=FI_6by0AAAAJ&hl=en" target="_blank">Google Scholar</a> &nbsp/&nbsp
                                <a href="https://github.com/supersglzc" target="_blank">GitHub</a>&nbsp/&nbsp
                                <a href="https://www.linkedin.com/in/zechu-li-66a7741b3/" target="_blank">LinkedIn</a>
                            </p>
                        </td>
                        <td width="33%">
                            <img src="images/selfie.jpg" style="display:block;" width="100%">
                        </td>
                    </tr>
                </table>

                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tr>
                        <td>
                            <heading>Research</heading>
                        </td>
                    </tr>
                </table>

                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <a href="https://ieeexplore.ieee.org/document/9827289" target="_blank">
                                <img src="images/social_learning.png" alt="sym" width="100%" style="border-radius:5px">
                            </a>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <papertitle>Social Learning In Markov Games: Empowering Autonomous Driving
                            </papertitle>
                            <br>
                            Xu Chen,
                            <strong>Zechu Li</strong>,
                            <a href="https://sharondi-columbia.wixsite.com/ditectlab">Sharon (Xuan) Di</a>
                            <br>
                            <em>IEEE Intelligent Vehicles Symposium (IV)</em>, 2022
                            <br>
                            <a href="https://ieeexplore.ieee.org/document/9827289" target="_blank">paper</a> /
                            <a href="https://github.com/supersglzc/Social-Learning">code</a>
                            <p></p>
                            <p>
                            We denoise images efficiently by predicting spatially-varying kernels at low resolution and using a fast fused op to jointly upsample and apply these kernels at full resolution.
                            </p>
                        </td>
                    </tr>
                </table>

                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                  <tr>
                      <td style="padding:20px;width:25%;vertical-align:middle">
                          <a href="https://arxiv.org/pdf/2112.05923.pdf" target="_blank">
                              <img src="images/erl_podracer.png" alt="sym" width="100%" style="border-radius:5px">
                          </a>
                      </td>
                      <td style="padding:20px;width:75%;vertical-align:middle">
                          <papertitle>ElegantRL-Podracer: Scalable and Elastic Library for Cloud-native Deep Reinforcement Learning
                          </papertitle>
                          <br>
                          <a href="http://www.tensorlet.org/">Xiaoyang Liu*</a>,
                          <strong>Zechu Li*</strong>,
                          <a href="https://www.princeton.edu/~zy6/">Zhuoran Yang</a>,
                          Jiahao Zheng,
                          <a href="https://zhaoranwang.github.io/">Zhaoran Wang</a>, <br>
                          <a href="http://www.bell-labs.com/about/researcher-profiles/anwarwalid/#gref">Anwar Walid</a>,
                          <a href="https://idea.edu.cn/person/guojian/">Jian Guo</a>,
                          <a href="http://people.eecs.berkeley.edu/~jordan/">Michael Jordan</a> [* Equal contribution]
                          <br>
                          <em>Deep Reinforcement Learning Workshop, NeurIPS</em>, 2021
                          <br>
                          <a href="https://arxiv.org/pdf/2112.05923.pdf" target="_blank">paper</a> /
                          <a href="https://github.com/AI4Finance-Foundation/ElegantRL">code</a>
                          <p></p>
                          <p>
                          We denoise images efficiently by predicting spatially-varying kernels at low resolution and using a fast fused op to jointly upsample and apply these kernels at full resolution.
                          </p>
                      </td>
                  </tr>
              </table>

              <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <a href="https://dl.acm.org/doi/10.1145/3490354.3494413" target="_blank">
                            <img src="images/finrl_podracer.png" alt="sym" width="100%" style="border-radius:5px">
                        </a>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <papertitle>FinRL-Podracer: High Performance and Scalable Deep Reinforcement Learning for Quantitative Finance
                        </papertitle>
                        <br>
                        <strong>Zechu Li*</strong>,
                        <a href="http://www.tensorlet.org/">Xiaoyang Liu*</a>,
                        Jiahao Zheng,
                        <a href="https://zhaoranwang.github.io/">Zhaoran Wang</a>, <br>
                        <a href="http://www.bell-labs.com/about/researcher-profiles/anwarwalid/#gref">Anwar Walid</a>,
                        <a href="https://idea.edu.cn/person/guojian/">Jian Guo</a> [* Equal contribution]
                        <br>
                        <em>ACM International Conference on AI in Finance (ICAIF)</em>, 2021
                        <br>
                        <a href="https://dl.acm.org/doi/10.1145/3490354.3494413" target="_blank">paper</a> /
                        <a href="https://github.com/AI4Finance-Foundation/FinRL_Podracer">code</a>
                        <p></p>
                        <p>
                        We denoise images efficiently by predicting spatially-varying kernels at low resolution and using a fast fused op to jointly upsample and apply these kernels at full resolution.
                        </p>
                    </td>
                </tr>
            </table>

                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                  <tr>
                      <td>
                          <heading>Open Source Projects</heading>
                      </td>
                  </tr>
              </table>

              <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                        <a href="https://github.com/AI4Finance-Foundation/ElegantRL" target="_blank">
                            <img src="images/elegantrl.jpg" alt="sym" width="100%" style="border-radius:5px">
                        </a>
                    </td>
                    <td style="padding:20px;width:75%;vertical-align:middle">
                        <papertitle>ElegantRL “小雅”: Massively Parallel Library for Cloud-native Deep Reinforcement Learning
                        </papertitle>
                        <br>
                        <a href="https://elegantrl.readthedocs.io/en/latest/index.html" target="_blank">project page</a> /
                        <a href="https://github.com/AI4Finance-Foundation/ElegantRL">code</a> /
                        <a class="github-button" href="https://github.com/AI4Finance-Foundation/ElegantRL" data-icon="octicon-star" data-show-count="true" aria-label="Star AI4Finance-Foundation/ElegantRL on GitHub" target="_blank">GitHub Star</a>
                        <p></p>
                        <p>
                        We denoise images efficiently by predicting spatially-varying kernels at low resolution and using a fast fused op to jointly upsample and apply these kernels at full resolution.
                        </p>
                    </td>
                </tr>
            </table>

            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
              <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                      <a href="https://github.com/AI4Finance-Foundation/FinRL" target="_blank">
                          <img src="images/finrl.png" alt="sym" width="100%" style="border-radius:5px">
                      </a>
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                      <papertitle>FinRL: Financial Reinforcement Learning
                      </papertitle>
                      <br>
                      <a href="https://finrl.readthedocs.io/en/latest/index.html" target="_blank">project page</a> /
                      <a href="https://github.com/AI4Finance-Foundation/FinRL">code</a> /
                      <a class="github-button" href="https://github.com/AI4Finance-Foundation/FinRL" data-icon="octicon-star" data-show-count="true" aria-label="Star AI4Finance-Foundation/FinRL on GitHub" target="_blank">GitHub Star</a>
                      <p></p>
                      <p>
                      We denoise images efficiently by predicting spatially-varying kernels at low resolution and using a fast fused op to jointly upsample and apply these kernels at full resolution.
                      </p>
                  </td>
              </tr>
          </table>

                    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                      <tr>
                          <td>
                              <heading>Book Chapter</heading>
                          </td>
                      </tr>
                  </table>
                  
                  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tr>
                        <td style="padding:20px;width:25%;vertical-align:middle">
                            <a href="https://www.sciencedirect.com/science/article/pii/B9780128244470000157" target="_blank">
                                <img src="images/book.jpg" alt="sym" width="100%" style="border-radius:5px">
                            </a>
                        </td>
                        <td style="padding:20px;width:75%;vertical-align:middle">
                            <papertitle>High-performance Tensor Decompositions for Compressing and Accelerating Deep Neural Networks
                            </papertitle>
                            <br>
                            <a href="http://www.tensorlet.org/">Xiaoyang Liu</a>,
                            Yiming Fang,
                            Liuqing Yang,
                            <strong>Zechu Li</strong>,
                            <a href="http://www.bell-labs.com/about/researcher-profiles/anwarwalid/#gref">Anwar Walid</a>
                            <br>
                            <em>Tensors for Data Processing</em>, 2022
                            <br>
                            <a href="https://www.sciencedirect.com/science/article/pii/B9780128244470000157" target="_blank">chapter</a> /
                            <a href="https://www.elsevier.com/books/tensors-for-data-processing/liu/978-0-12-824447-0">book</a>
                            <p></p>
                            <p>
                            We denoise images efficiently by predicting spatially-varying kernels at low resolution and using a fast fused op to jointly upsample and apply these kernels at full resolution.
                            </p>
                        </td>
                    </tr>
                </table>

                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tbody>
                        <tr>
                            <td>
                                <br>
                                <p align="right">
                                    <font size="2">
                                        <a href="https://people.eecs.berkeley.edu/~barron/" target="_blank">This guy makes a nice webpage.</a>
                                    </font>
                                </p>
                            </td>
                        </tr>
                    </tbody>
                </table>
                <!-- Global site tag (gtag.js) - Google Analytics -->
                <script async src="https://www.googletagmanager.com/gtag/js?id=UA-79592980-2"></script>
                <script>
                    window.dataLayer = window.dataLayer || [];

                    function gtag() {
                        dataLayer.push(arguments);
                    }
                    gtag('js', new Date());

                    gtag('config', 'UA-79592980-2');
                </script>

            </td>
        </tr>
    </table>
</body>

</html>
